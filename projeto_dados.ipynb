{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3200c32",
   "metadata": {},
   "source": [
    "# Projeto - Crédito para Financiamento de Imóveis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72dc29c",
   "metadata": {},
   "source": [
    "## Orientações gerais\n",
    "\n",
    "O projeto de encerramento de curso será dividido em três partes e utilizado como avaliação dos módulos de Data Engineering, Data Science e AWS.\n",
    "\n",
    "## Contextualização\n",
    "\n",
    "A PyCoders Ltda., cada vez mais especializada no mundo da Inteligência Artificial e Ciência de Dados, foi procurada por uma fintech para desenvolver um projeto de concessão de crédito para imóveis. Nesse projeto, espera-se a criação de score que discrimine ao máximo os bons pagadores dos maus pagadores. Para isso, foi disponibilizada uma base de dados com milhares de casos de empréstimos do passado, com diversas características dos clientes. Deve ser entregue um modelo para realizar essa classificação. Por questões contratuais, o pagamento será realizado baseado no desempenho (ROC AUC).\n",
    "\n",
    "\n",
    "## Base de Dados\n",
    "\n",
    "Serão utilizadas bases de dados com informações cadastrais, histórico de crédito e balanços financeiros de diversos clientes. O conjunto de dados está dividido em treino e teste, todos no formato csv. Toda a modelagem, validação e avaliação deve ser feita em cima do conjunto de treino, subdividindo tal base como achar melhor. Existe também a base das variáveis explicativas, para ajudar no desenvolvimento do projeto.\n",
    "\n",
    "[Baixar aqui](https://s3-sa-east-1.amazonaws.com/lcpi/0694c90a-7782-47f7-8bbc-e611d31f9f21.zip)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad36db4",
   "metadata": {},
   "source": [
    "# Parte 1: Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6476b0",
   "metadata": {},
   "source": [
    "**Preparação:** Salve os arquivos `.csv` em `/FileStore/tables/projeto_credito/`, sem alterar seus nomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3311447",
   "metadata": {},
   "source": [
    "## Antes de modelar\n",
    "\n",
    "1. Crie um `fluxo de dados` no Databricks para as bases que serão utiizadas.\n",
    "    1. Insira os dados brutos na primeira camada.\n",
    "    1. Salve as transformações / limpezas na segunda camada.\n",
    "   \n",
    "    1. Crie uma pipeline para o processo.\n",
    "        1. Pipeline, nesse caso, será um único script que gere todas as tabelas acima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30f7257",
   "metadata": {},
   "source": [
    "## Durante a modelagem\n",
    "\n",
    "1. Selecione e salve as colunas relevantes e features criadas na terceira camada.\n",
    "\n",
    "1. Salve as versões do modelo no formato `pickle` no DBFS.\n",
    "\n",
    "1. Mantenha o controle das versões criando uma tabela no formato\n",
    "**ATENÇÂO:** Como estamos na versão community, lembre de exportar a tabela abaixo para o DBFS antes da sessão encerrar.\n",
    "\n",
    "|id_modelo|nome_modelo|data_treino|método|roc_auc|tempo_de_treino(s)|hyperparametros|path_to_pickle\n",
    "|---|---|---|---|---|---|---|---|\n",
    "|1|RandomForestRapida|2022-02-22|Random Forest Simples|0.76|124|\\[max_depth=4, ...\\]|/FileStore/tables/modelos/...|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18996267",
   "metadata": {},
   "source": [
    "## Após modelar\n",
    "\n",
    "1. Salve os dados de treino e validação em uma tabela (para que seja possível reproduzir resultados no futuro).\n",
    "    1. Crie uma coluna com o id do modelo escolhido para refêrencia. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125f7f04",
   "metadata": {},
   "source": [
    "## Regras de Entrega\n",
    "\n",
    "1. Um notebook (databricks) com a pipeline que gere as tabelas da fase *Antes de modelar*. O notebook deve rodar de uma vez só!\n",
    "\n",
    "1. Um arquivo `.csv` com as informações da tabela gerada na fase *Durante a modelagem*.\n",
    "\n",
    "1. Um notebook que gere as tabelas de treino e validação do passo *Após modelar*. O notebook deve rodar de uma vez só!\n",
    "\n",
    "> **IMPORTANTE:** Tendo em vista que não teremos apresentação do projeto (e não queromos pedir que vocês gravem um vídeo explicando o notebook, haha), é indispensável que ele esteja organizado e comentado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17c3101",
   "metadata": {},
   "source": [
    "# Parte 2: Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7466f8d",
   "metadata": {},
   "source": [
    "## Requisitos Obrigatórios do Projeto\n",
    "\n",
    "1. **Análise Exploratória dos Dados:** análise descritiva dos dados numéricos e categóricos, bem como gráficos (de sua preferência).\n",
    "2. **Data Cleaning:** a base de dados apresenta dados ausentes. Sendo assim, você deverá realizar uma limpeza dos dados, removendo-os ou preenchendo com valores coerentes.\n",
    "3. **Conversão de variáveis categóricas**\n",
    "4. **Balanceamento de amostras:** nesse caso, como o dataset possui muitas amostras, você pode utilizar o NearMiss para realizar um *under sampling*.\n",
    "5. **Machine Learning:** aplique algum algoritmo de ML, de sua preferência, dividindo o seu conjunto de dados em treino e teste, para obter o `roc_auc_score` de ambos os cenários (treino e teste)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9da576",
   "metadata": {},
   "source": [
    "## Regras de Entrega\n",
    "\n",
    "1. Deve ser entregue uma base com as predições para a base de teste.\n",
    "    - Essa base deverá ser um Data Frame com duas colunas: a primeira sendo o SK_ID_CURR e a segunda a probabilidade de inadimplência.\n",
    "    - ⚠️ Entregar as predições com a probabilidade da inadimplência ocorrer.\n",
    "2. Deve ser entregue o notebook com as etapas que foram aplicadas na criação do modelo (especificadas na subseção anterior).\n",
    "\n",
    "> **IMPORTANTE:** Tendo em vista que não teremos apresentação do projeto (e não queromos pedir que vocês gravem um vídeo explicando o notebook, haha), é indispensável que ele esteja organizado e comentado.\n",
    "\n",
    "<a href=\"https://s3-sa-east-1.amazonaws.com/lcpi/94acac51-8ce4-465b-a06d-a1cf19ec5d93.ipynb\" style=\"display: block; background-color: #222; padding: 20px; text-align: center; font-weight: 600;\">\n",
    "Clique aqui para fazer o download do notebook com as instruções.\n",
    "</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "238.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
